\chapter{Completed Work}
\label{ch:completed}
Work in this chapter has been published in \newcite{Ferracane:2016}, \newcite{Ferracane:2017}, \newcite{Ferracane:2019:naacl}, and \newcite{Ferracane:2019:acl}.

\section{Chapter Overview}
In my completed work, I tackle the question of whether discourse can help on certain NLP tasks. With positive results in this area, I next explore annotating discourse, both in a supervised and unsupervised manner. Here I instead meet with negative results which motivate my proposed work (Chapter \ref{ch:proposed}).

\section{Does discourse help?}
I first examine whether traditional discourse analyses and theories are helpful on downstream NLP tasks. Discourse can focus on very small linguistic units such as a single word ``the'' (to distinguish between new and old information) or multiple sentences (to understand the rhetorical relation between propositions). I first focus on the smaller units, studying how coreference can be used as a marker of salience for information extraction in medical texts. Next, I focus on the larger units, specifically in the framework of Rhetorical Structure Theory \citep[RST;][]{Mann:1988}. I experiment with different representations of RST discourse relations for the task of authorship attribution.

\subsection{Background}
I first give a brief overview of the discourse theories that are relevant to these works-- coreference resolution and RST. 

\noindent {\bf Automated coreference resolution.}
The goal of coreference resolution is to determine which mentions in a text refer to the same entity. A referring expression, or \textit{mention}, is the natural language expression used by discourse participants to refer to entities. Two or more mentions that refer to the same entity are coreferent, and together form a \textit{coreference chain}. An anaphor and its antecedent (or cataphor and its postcedent) will form a coreference chain. Mentions can be indefinite noun phrases, definite noun phrases, proper names and pronouns.

Resolving these coreferences automatically is a long-studied task that remains a challenging problem.
%(even state-of-the-art models are able to achieve an average of only 73.0 F1 on the CoNLL 2012 Shared Task). 
In this work, we use an off-the-shelf coreference resolver \cite{Clark:2015} to extract coreference chains in abstracts of clinical trial reports. In the medical area, coreference resolution has been most closely studied for analyzing clinical narrative text (e.g.,  in electronic health records) and bio-molecular studies. Despite the active interest in coreference resolution, there has been much less research investigating its application to reports of clinical trials. To the best of our knowledge, we are the first to use coreference features to identify study groups in clinical trial abstracts. 

\noindent {\bf Rhetorical Structure Theory (RST).} The principal underlying RST is that coherent texts consist of minimal units which are linked to each other, recursively, through rhetorical relations \cite{Mann:1988}. Thus, the goal of RST is to describe the rhetorical organization of a text by using a hierarchical structure that captures the communicative intent of the writer. The first step in RST is to divide the text into elementary discourse units (EDUs), which generally correspond to clauses. Two adjacent EDUs are related to each other by a discourse relation. The EDU that is more central to the text's purpose is labelled as the \textit{nucleus}, and the other (usually subordinating) EDU as the \textit{satellite}.
%This relation is characterized as either paratactic or hypotactic. In the more common hypotactic relation, typically identified with subordination,  In the paratactic relation, typically identified with coordination, all EDUs are labelled as \textit{nucleus}. 
These relations are then incrementally grouped together with other relations until forming a tree that spans the entire document.
RST has been widely adopted by the research community in part because trees are a structure amenable to computational algorithms, and in part because of the existence of a carefully annotated corpus (RST Discourse Treebank, \citet{[RST-DT;][]Carlson:2001}). Using RST discourse trees has shown to help many NLP end tasks, including summarization \cite{Hirao:2013,Durrett:2016}, machine translation \cite{Joty:2017}, sentiment analysis \cite{Ji:2017}, and in this work we apply it to authorship attribution.

\subsection{Coreference and salience for information extraction} 
In \newcite{Ferracane:2016}, we show coreference is useful for identifying salient information in medical texts. Our task is to automatically identify the population groups (or arms) participating in a clinical trial, as described in abstracts of clinical trial reports. Identifying this oft-overlooked piece of information is useful in synthesizing results across multiple clinical studies that form part of a systematic review in evidence-based medicine. A classification model that performs better with features extracted from coreference chains supports the intuition that coreference is able to capture the discourse salience of groups, and in particular the experimental groups. Interestingly, our error analysis shows these features also identify other salient information such as trial outcomes, another key piece of information needed in systematic reviews.
%We note that the (less salient) control arms do not benefit as much from these features.

\subsection{Discourse embeddings for authorship attribution}
In \newcite{Ferracane:2017}, we present a novel method to embed discourse features in a convolutional neural network (CNN) model. Our task is authorship attribution: given a text and a set of authors, identify the author of that text. Prior work hypothesized that every author has a unique way of describing and developing characters or other entities in a text, and showed that exploiting these patterns with RST discourse relations is helpful for the task \cite{Feng:2014}. However, a more recent non-discourse CNN model is able to outperform this (non-neural network) prior work. We thus explore techniques to embed and maximize the effectiveness of discourse information in a strong baseline CNN model.
We find that tracking the RST discourse relations of entities across an entire document and embedding this sequence works best and is able to significantly outperform the non-discourse baseline.

\section{Annotating discourse} 
Having confirmed that discourse is helpful on some NLP end tasks, I next focus on addressing the practical limitations of the RST-DT annotated corpus, which is smaller in size and only covers the news domain. Many works attempt to circumvent these restrictions, for example by tailoring the label taxonomy to their domain or task, or by considering only intra vs. inter-sentential structures \cite{daCunha:2007,Bhatia:2015,Hogenboom:2015}. In order to analyze discourse for any task or domain, I first  examine learning latent representations of discourse that do not require direct supervision. With negative results in this work, I alternatively examine the feasibility of manually annotating discourse in medical documents to expand beyond news. I encounter significant difficulties here, as well, which motivate my proposed work in Chapter \ref{ch:proposed}.

\subsection{Background}
I here review prior works that induce latent structures as a means to learn linguistic structures in an unsupervised fashion.

\noindent {\bf Unsupervised latent structures.} Inducing structure without direct supervision has been a recent popular approach in syntax \cite{Yogatama:2017,Choi:2018,Bisk:2018}. The models induce structure over a sentence meant to represent a syntax parse tree, while only receiving supervision on a downstream task such as natural language inference. These models are able to outperform those using explicit parse trees on many tasks. However, evaluations of the latent trees show they are inconsistent across random initializations of the model, are shallower than their explicitly parsed counterparts (Penn Treebank parses) and do not resemble any linguistic syntax theory \cite{Williams:2018}.

Moving from representing a single sentence to an entire document, \newcite{Liu:2018} induce a structured attention over an entire document that can be parsed as a non-projective dependency tree. In this work, we examine whether this unsupervised structure can be interpreted as representing the discourse of a text, and compare it to (unlabeled) RST discourse trees.

\subsection{Unsupervised: latent discourse representations} 
In \newcite{Ferracane:2019:acl}, I analyze and evaluate latent structures as an unsupervised means to learn discourse beyond the domain of news (RST-DT is comprised of only WSJ articles) and to not be constrained to small-data settings (RST-DT is a smaller corpus with only 425 documents).  Learning \emph{latent} representations of discourse in an unsupervised fashion is furthermore an attractive alternative to acquiring expensive training data from expert annotators. \citet{Liu:2018} propose a structured attention for text classification that derives a tree over a text, akin to an RST discourse tree. We examine this model in detail, and evaluate on additional discourse-relevant tasks and datasets, in order to assess whether the structured attention improves performance on the end task and, more importantly, whether it captures a text's discourse structure. We find the learned latent trees are shallow and instead focus on lexical cues. Even after obtaining deeper trees with proposed model modifications, the trees are still far from discourse when compared to parsed RST discourse dependency trees. Finally, ablation studies show the structured attention provides little benefit for the end tasks, sometimes even hurting performance. I conclude that learning a discourse representation in this unsupervised fashion is not possible.

\subsection{Supervised: annotating RST-style discourse in the medical domain} With negative results for the unsupervised approach, I next turn to manual annotation for a supervised approach. I choose to annotate medical documents to expand beyond the domain of news because understanding discourse in this area is useful to a wide community of researchers beyond NLP and can have direct, beneficial applications. In \newcite{Ferracane:2019:naacl}, I present the first small-scale medical corpus in English that is annotated with RST discourse segments (though not the full structures). Moving from news to medical, we encounter formatting and syntactic differences that affect segmentation. However, the more problematic issues arise in annotating the entire discourse structure (the labeled tree). During the annotation phase, each of the two annotators, without having consulted each other, adopted opposite strategies for creating the tree (top-down vs. bottom-up) which both seemed valid, but resulted in vastly different structures. We struggled with theorizing the intent of the writer and often encountered conflicting label annotations. 

%\section{Prior Work}

\section{Chapter Summary}
In my completed work, I show discourse is useful for two NLP tasks (information extraction and authorship attribution). However, I also find the application of RST to vary widely in which parts and how the theory is applied, in part because of the RST-DT corpus-- it is small and limited to the news domain. I first attempt to circumvent needing annotations with an unsupervised approach that learns a latent structure for a document. However, I find these structures are not interpretable as discourse. I then investigate the costlier route of manually annotating discourse in the medical domain, but also encounter significant difficulties which lead to the propsoed work in Chapter \ref{ch:proposed}.

