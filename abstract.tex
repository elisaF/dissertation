Understanding the discourse of a text necessitates an understanding of how propositions are structured and organized, a challenging task for computational models. But discourse also involves ambiguity, which sometimes opens the door for subjective interpretations.

In this thesis, I first examine how discourse information can be abstracted for effective use by computational models on downstream NLP tasks. Because these methods suffer from data scarcity, I explore other ways to learn discourse structure. An unsupervised approach is not able to learn the rich information encoded in discourse, while a manual annotation of discourse rediscovers the possibility of multiple interpretations. I seize on this result to focus on eliciting and analyzing subjective interpretations of discourse.
